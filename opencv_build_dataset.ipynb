{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### OpenCV-Python is a library of Python bindings designed to solve computer vision problems.\n",
    "\n",
    "OpenCV supports a wide variety of programming languages such as C++, Python, Java, etc., and is available on different platforms including Windows, Linux, OS X, Android, and iOS.\n",
    "\n",
    "OpenCV-Python makes use of Numpy, which is a highly optimized library for numerical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### open webcam and capture a frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam = cv2.VideoCapture(0)\n",
    "ret ,frame = webcam.read()\n",
    "print (ret)\n",
    "webcam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### webcam.read(): returns a frame and boolean value(True/False)..if frame is read correctly, it will be True. \n",
    "\n",
    "#### webcam.release() :to close webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"opencv_2\", frame)\n",
    " \n",
    "# Press any key to close external window\n",
    "cv2.waitKey(0)   \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv.waitKey() is a keyboard binding function. Its argument is the time in milliseconds. The function waits for specified milliseconds for any keyboard event. If you press any key in that time, the program continues. If 0 is passed, it waits indefinitely for a key stroke\n",
    "\n",
    "\n",
    "#### cv.destroyAllWindows() simply destroys all the windows we created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To create external window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('open_cv', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('open_cv',frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### matplotlib support RGB and opencv support BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_RGB = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(frame_RGB)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and Write Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('images/picture_RGB.jpg',frame_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture = cv2.imread('images/picture_RGB.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-17c2bbd9a33c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpicture\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[0;32m   3203\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3204\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3205\u001b[1;33m                         **kwargs)\n\u001b[0m\u001b[0;32m   3206\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3207\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1855\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5485\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    647\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[0;32m    648\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[1;32m--> 649\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Image data cannot be converted to float\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m         if not (self._A.ndim == 2\n",
      "\u001b[1;31mTypeError\u001b[0m: Image data cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(picture)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open connection to camera\n",
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "#External Window or in Notebook\n",
    "cv2.namedWindow(\"opencv_1\", cv2.WINDOW_AUTOSIZE)\n",
    " \n",
    "while True:\n",
    "      \n",
    "    ret, frame = webcam.read()\n",
    "    cv2.imshow(\"opencv_1\", frame) \n",
    "     \n",
    "    # Press q for close window\n",
    "    #here 10 is a milliseconds\n",
    "    if cv2.waitKey(10)== ord('q'):\n",
    "        break\n",
    "webcam.release()        \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detection using Haar Cascades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of available pretraied models in OpenCV:\n",
    "\n",
    "<div style=\"float: left; width: 50%\">\n",
    "<ul>\n",
    "    <li> haarcascade_eye_tree_eyeglasses  \n",
    "    <li> haarcascade_mcs_leftear\n",
    "    <li> haarcascade_eye                  \n",
    "    <li> haarcascade_mcs_lefteye\n",
    "    <li> haarcascade_frontalface_alt2   \n",
    "    <li> haarcascade_mcs_mouth\n",
    "    <li> haarcascade_frontalface_alt_tree\n",
    "    <li> haarcascade_mcs_nose\n",
    "    <li> <font style=\"color: #be2830\">haarcascade_frontalface_alt</font>       \n",
    "    <li> haarcascade_mcs_rightear\n",
    "    <li> haarcascade_frontalface_default\n",
    "</ul>\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%\">\n",
    "<ul>\n",
    "    <li> haarcascade_mcs_righteye\n",
    "    <li> haarcascade_fullbody            \n",
    "    <li> haarcascade_mcs_upperbody\n",
    "    <li> haarcascade_lefteye_2splits    \n",
    "    <li> haarcascade_profileface\n",
    "    <li> haarcascade_lowerbody            \n",
    "    <li> haarcascade_righteye_2splits\n",
    "    <li> haarcascade_mcs_eyepair_big     \n",
    "    <li> haarcascade_smile\n",
    "    <li> haarcascade_mcs_eyepair_small\n",
    "    <li> haarcascade_upperbody\n",
    "</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Faces with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detector = cv2.CascadeClassifier( xml_file_path)\n",
    "\n",
    "### face_coord = detector.detectMultiScale(image, scale_factor, min_neighbors, min_size, max_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### image : gray scale image where face are detected.\n",
    "\n",
    "\n",
    "#### scale_factor:Parameter specifying how much the image size is reduced at each image scale.\n",
    "\n",
    "\n",
    "#### minNeighbors – Parameter specifying how many neighbors each candidate rectangle should have to retain it.\n",
    "\n",
    "\n",
    "#### minSize – Minimum possible object size. Objects smaller than that are ignored.\n",
    "\n",
    "\n",
    "#### maxSize – Maximum possible object size. Objects larger than that are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "faceDetect=cv2.CascadeClassifier('xml/frontal_face.xml')\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow(\"Face\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "while True:\n",
    "    ret,img = cam.read()\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceDetect.detectMultiScale(gray,scaleFactor=1.2,minNeighbors=5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"Face\",img)\n",
    "    if (cv2.waitKey(10)== ord('q')):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\" style='color: #be2830'>Build Our Dataset</h2>\n",
    "<h4 align=\"center\">\n",
    "Detect $\\rightarrow$ Cut $\\rightarrow$ Normalize $\\rightarrow$ Resize $\\rightarrow$ Save</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detect face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(frame):\n",
    "    if frame.ndim!=2:\n",
    "        frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    detector = cv2.CascadeClassifier(\"xml/frontal_face.xml\")\n",
    "\n",
    "    faces = detector.detectMultiScale(frame,1.2,5)\n",
    "    \n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_scale(image):\n",
    "    if image.ndim!=2:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_faces(image, faces_coord):\n",
    "    faces = []\n",
    "      \n",
    "    for (x, y, w, h) in faces_coord:\n",
    "        \n",
    "        faces.append(image[y: y + h, x : x + w ])\n",
    "         \n",
    "    return faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize faces by increasing pixel intensity(brightness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_intensity(images):\n",
    "    images_norm = []\n",
    "    for image in images:\n",
    "        is_color = len(image.shape) == 3 \n",
    "        if is_color:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        images_norm.append(cv2.equalizeHist(image))\n",
    "    return images_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize\n",
    "\n",
    "#### cv.INTER_AREA for shrinking & cv.INTER_CUBIC for zooming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(images,size=(47,62)):\n",
    "    image_resize = []\n",
    "    \n",
    "    for image in images:\n",
    "        if image.shape < size:\n",
    "            img_size = cv2.resize(image,size,interpolation=cv2.INTER_CUBIC)\n",
    "        else:\n",
    "            img_size = cv2.resize(image,size,interpolation=cv2.INTER_AREA)\n",
    "        image_resize.append(img_size)\n",
    "        \n",
    "    return image_resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_faces(frame, faces_coord):\n",
    "    gray_frame = gray_scale(frame)\n",
    "    faces = cut_faces(gray_frame, faces_coord)\n",
    "    faces = normalize_intensity(faces)\n",
    "    \n",
    "    faces = resize(faces)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_show(image,title=\"\"):\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.imshow(image,cmap=\"Greys_r\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle(image, coords):\n",
    "    for (x, y, w, h) in coords:\n",
    "        #w_rm = int(0.2 * w / 2) \n",
    "        cv2.rectangle(image, (x , y), (x + w , y + h), (0,0,255),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "#cv2.namedWindow(\"Face\", cv2.WINDOW_AUTOSIZE)\n",
    "folder = \"people/\"+input('Person:').lower()\n",
    "\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "    \n",
    "    flag_start_capturing = False\n",
    "    sample=1\n",
    "    #cam = cv2.VideoCapture(0)\n",
    "    cv2.namedWindow(\"Face\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "    while True:\n",
    "        ret,frame = cam.read()\n",
    "        \n",
    "        \n",
    "        \n",
    "        faces_coord = detect_face(frame)\n",
    "\n",
    "        if len(faces_coord):\n",
    "            faces = normalize_faces(frame,faces_coord)\n",
    "            #faces = normalize_intensity(faces)\n",
    "            cv2.imwrite(folder + '/' + str(sample)+'.jpg',faces[0])\n",
    "            plot_show(faces[0],\"Image saved:\"+str(sample))\n",
    "            clear_output(wait=True)\n",
    "            if flag_start_capturing == True:\n",
    "                sample += 1\n",
    "            \n",
    "        draw_rectangle(frame,faces_coord)\n",
    "        cv2.imshow('Face',frame)\n",
    "        keypress=cv2.waitKey(1)\n",
    "        \n",
    "        if keypress == ord('c'):\n",
    "            \n",
    "            if flag_start_capturing == False:\n",
    "                flag_start_capturing = True\n",
    "            \n",
    "        \n",
    "        if sample >15:\n",
    "            break\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print (\"This name already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset for unknown people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### datasets for other class\n",
    "\n",
    "basepath = 'C:\\\\Users\\\\Vineet\\\\scikit_learn_data\\\\lfw_home\\\\lfw_funneled\\\\'\n",
    "#C:\\Users\\Vineet\\scikit_learn_data\\lfw_home\n",
    "images = os.listdir(basepath) \n",
    "print (len(images))\n",
    "data = images[:210]\n",
    "\n",
    "for i,folder in enumerate(data,start=1):\n",
    "    \n",
    "    files=os.listdir(basepath+'\\\\'+folder)\n",
    "    for k,img in enumerate(files,start=1):\n",
    "        if img.endswith('.jpg'):\n",
    "            #print img\n",
    "            frame=cv2.imread(basepath+'\\\\'+folder+'\\\\'+img,0)\n",
    "        #print frame\n",
    "       \n",
    "            faces_coord = detect_face(frame)\n",
    "            if len(faces_coord):\n",
    "                faces = cut_faces(frame, faces_coord)\n",
    "                #print faces\n",
    "                faces = normalize_intensity(faces)\n",
    "                faces = resize(faces)\n",
    "                cv2.imwrite('people/unknown/' + str(i)+'.jpg',faces[0])\n",
    "                \n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collect dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_dataset():\n",
    "    images = []\n",
    "    labels = []\n",
    "    labels_dic = {}\n",
    "    #people = [person for person in os.listdir(\"Male_female/\")]\n",
    "    people = [person for person in os.listdir(\"people/\")]\n",
    "    #people = [person for person in os.listdir(\"people/\")]\n",
    "    for i, person in enumerate(people):\n",
    "        labels_dic[i] = person\n",
    "        for image in os.listdir(\"people/\" + person):\n",
    "            if image.endswith('.jpg'):\n",
    "                images.append(cv2.imread(\"people/\" + person + '/' + image, 0))\n",
    "                labels.append(i)\n",
    "    return (images, np.array(labels), labels_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, labels_dic = collect_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(images))\n",
    "print (labels_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=X_train.reshape(len(X_train),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(train.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1 = PCA(n_components=.97)\n",
    "new_train=pca1.fit_transform(X_train_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV,KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf=KFold(n_splits=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C':[.0001,.001,.01,.1,1,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_svc = GridSearchCV(SVC(kernel='linear',probability=True),param_grid=param_grid,cv=kf,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_svc.fit(new_train,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_svc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=gs_svc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filename = 'svc_linear_face.pkl'\n",
    "f=open(filename, 'wb')\n",
    "pickle.dump(clf,f)\n",
    " \n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'svc_linear_face.pkl'\n",
    "svc1 = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(1)\n",
    "font=cv2.FONT_HERSHEY_PLAIN\n",
    "cv2.namedWindow(\"opencv_face\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret,frame = cam.read()\n",
    "    \n",
    "    \n",
    "    faces_coord = detect_face(frame) # detect more than one face\n",
    "    if len(faces_coord):\n",
    "        faces = normalize_faces(frame, faces_coord)\n",
    "        #faces = normalize_intensity(faces)\n",
    "        for i, face in enumerate(faces): # for each detected face\n",
    "            \n",
    "            \n",
    "            #cv2.imwrite('trainingData/female/picture_BGR5.jpg',face)\n",
    "            t=face.reshape(1,-1)\n",
    "            t=sc.transform(t.astype(np.float64))\n",
    "            test = pca1.transform(t)    \n",
    "            #print test\n",
    "            #transform = test.reshape(1,-1)\n",
    "            #print transform\n",
    "            prob=svc1.predict_proba(test)\n",
    "            confidence = svc1.decision_function(test)\n",
    "            print (confidence)\n",
    "            print (prob)\n",
    "           \n",
    "            \n",
    "            \n",
    "            pred = svc1.predict(test)\n",
    "            print (pred,pred[0])\n",
    "           \n",
    "            name=labels_dic[pred[0]].capitalize()\n",
    "            print (name)\n",
    "            \n",
    "            #pred = labels_dic[pred[0]].capitalize()\n",
    "            #threshold = .50\n",
    "            \n",
    "            \n",
    "                \n",
    "            cv2.putText(frame,name,(faces_coord[i][0], faces_coord[i][1] - 10),\n",
    "                       cv2.FONT_HERSHEY_PLAIN, 2, (66, 53, 243), 2)\n",
    "            \n",
    "                \n",
    "           \n",
    "           # if prob[0][1]>.85:\n",
    "                \n",
    "            #    cv2.putText(frame, 'vineet',(faces_coord[i][0], faces_coord[i][1] - 10),\n",
    "             #               cv2.FONT_HERSHEY_PLAIN, 2, (66, 53, 243), 2)\n",
    "            \n",
    "                \n",
    "            #else:\n",
    "             #   cv2.putText(frame,'unknown',(faces_coord[i][0], faces_coord[i][1] - 10),\n",
    "              #              cv2.FONT_HERSHEY_PLAIN, 3, (66, 53, 243), 2)\n",
    "                \n",
    "                \n",
    "           \n",
    "        clear_output(wait = True)\n",
    "        draw_rectangle(frame, faces_coord) # rectangle around face\n",
    "        \n",
    "    cv2.putText(frame, \"ESC to exit\", (5, frame.shape[0] - 5),cv2.FONT_HERSHEY_PLAIN, 1.3, (66, 53, 243), 2,\n",
    "                cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow(\"opencv_face\", frame) # live feed in external\n",
    "    if cv2.waitKey(5) == 27:\n",
    "        break\n",
    "        \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
